#!/usr/bin/env python

# This script generates trees and tables for inclusion in the LaTeX version
# of the threat model document.
#
# Usage: generate_latex_inputs [db_file]
#
# Daniel M. Zimmerman, January 2025
# Copyright (C) 2025 Free & Fair

import argparse
import re
from natsort import natsorted
from pathlib import Path

# our shared database functions
from read_database import build_data_structures

# global data structures
property_dict = None
context_dict = None
mitigation_dict = None
attack_dict = None

def sanitize_text(text):
    """ Sanitize text by replacing newlines with spaces.

        :param text: The text to sanitize (as a single string).
        :returns: The sanitized text (as a single string).
    """
    return text.replace('\n', ' ')

def add_link(m):
    """ Create a LaTeX hyperref link or citation by looking for
        specific patterns of braces and linking it to anchors for
        autogenerated IDs, general document anchors, or citation keys.

        :param m: The regex match representing a presumed hyperlink.
        :returns: The LaTeX hyperlink, or the original string if one cannot
                  be constructed.
    """
    orig_link = m.group(1)

    # strip off the { and }
    bare_link = orig_link[1:-1]

    # if the link is of the form [x][y], it needs to be a hyperlink
    # with text x to anchor y; if it is of the form [[x]], it needs
    # to be a citation of x. Otherwise, it's a reference to an identifier
    # of something in the threat model.

    if str.startswith(bare_link, '[[') and str.endswith(bare_link, ']]'):
        # extract the cite key and create the citation
        cite_key = bare_link[2:-2]
        if len(cite_key) > 0:
            return f'\\cite{{{cite_key}}}'
        else:
            print(f'invalid citation {orig_link}, aborting')
            exit(1)
    elif str.startswith(bare_link, '[') and str.endswith(bare_link, ']') and \
         str.count(bare_link, '][') == 1:
        # extract the link text and link target
        div_index = str.index(bare_link, '][')
        link_target = bare_link[1:div_index]
        link_text = bare_link[(div_index + 2):-1]
        # sanity check
        if '[' in link_text or ']' in link_text or \
           '[' in link_target or ']' in link_target:
            print(f'invalid targeted link {orig_link}, aborting')
            exit(1)
        else:
            return f'\\hyperlink{{{link_target}}}{{{link_text}}}'

    else:
        # find the item with the linked identifier;
        # it could be in any one of the tables
        candidates = []
        candidates.extend([p for p in property_dict.values() if p['identifier'] == bare_link])
        candidates.extend([c for c in context_dict.values() if c['identifier'] == bare_link])
        candidates.extend([m for m in mitigation_dict.values() if m['identifier'] == bare_link])
        candidates.extend([a for a in attack_dict.values() if a['identifier'] == bare_link])
        if len(candidates) == 0:
            print(f'invalid link {orig_link}, aborting')
            exit(1)
        elif len(candidates) > 1:
            print(f'non-unique link {orig_link}, aborting')
            exit(1)
        else:
            if candidates[0] in context_dict.values():
                # we use the straight identifiers for contexts
                candidate_auto_id = candidates[0]['identifier']
            else:
                candidate_auto_id = candidates[0]['auto_identifier']
            hyperlink = f'\\hyperlink{{{candidate_auto_id}}}{{{candidate_auto_id}}}'
            return hyperlink

def create_links_in_line(line):
    """ Add LaTeX hyperlinks to an entire line of text by repeatedly calling
        add_link() with text within braces.

        :param line: The line of text.
        :returns: The line of text with added hyperlinks.
    """
    return re.sub(r"({.*?})", add_link, line)

def build_property_list(property, level=0, prefix='', excludes=[]):
    """ Recursively build a list of properties, starting from a specific
        property, in LaTeX itemized list format.

        :param property: The property to start the list from.
        :param level: The level at which we are starting, default 0.
        :param prefix: The prefix for the list line (to make reasonable LaTeX).
        :returns: The list, as a list of strings.
    """
    lines = []

    if level > 0: # don't make a list item for the tree root
        name = property['name']
        if name not in excludes:
            description = create_links_in_line(sanitize_text(property['description'] or ''))
            auto_id = property['auto_identifier']
            lines.append(f'{prefix}  \\item \\hypertarget{{{auto_id}}}{{{auto_id}}}. {description}')

    if len(property['children']) > 0:
        if level == 0:
            child_prefix = '  '
        else:
            child_prefix = prefix + '  '
        lines.append(f'{child_prefix}\\begin{{itemize}}')
        for i, child in enumerate(property['children']):
            lines.extend(build_property_list(child, level + 1, child_prefix, excludes=excludes))
        lines.append(f'{child_prefix}\\end{{itemize}}')

    return lines

def build_context_table():
    """ Build a LaTeX tabularray long table for the system contexts.

        :returns: The table, as a list of strings.
    """
    lines = []
    lines.append('\\begin{longtblr}{colspec={||Q[halign=l,valign=m]|Q[halign=l,valign=m]|Q[halign=l,valign=m]||}, rowhead=1, cells={font=\\fontsize{9pt}{10pt}\\selectfont}, row{1}={font=\\bfseries}}')
    lines.append('\\hline')
    lines.append('Abbreviation & Entity Name & Entity Type \\\\')
    lines.append('\\hline')
    sorted_contexts = natsorted(context_dict.values(), key=lambda context: context['identifier'] or '')
    for context in sorted_contexts:
        id = context['identifier']
        lines.append(f'\\hypertarget{{{id}}}{{{id}}} & {context['name']} & {context['kind']} \\\\')
        lines.append('\\hline')
    lines.append('\\end{longtblr}')
    return lines

def get_child_attacks(parent):
    """ Find all the child attacks for a specified parent attack, recursively.

        :param parent: The parent attack.
        :returns: A list of child attacks (can be empty).
    """
    result = []
    for child in parent['children']:
        # by default, the child inherits the parent's rationale
        result.append({
            'identifier': child['identifier'],
            'auto_identifier': child['auto_identifier']
        })
        result.extend(get_child_attacks(child))
        if child['is_abstract']:
            result.extend(get_instance_attacks(child))
    return result

def get_instance_attacks(abstract):
    """ Find all the instance attacks for a specified abstract attack.

        :param abstract: The abstract attack.
        :returns: A list of instance attacks (can be empty).
    """
    result = []
    for instance in attack_dict.values():
        if instance['instance_of'] == abstract:
            # it's an instance of the abstract attack
            result.append({
                'identifier': instance['identifier'],
                'auto_identifier': instance['auto_identifier']
            })
            result.extend(get_child_attacks(instance))
    return result

def get_mitigation_attacks(mitigation_id):
    """ Find the attacks that are mitigated by the specified mitigation.

        :param mitigaiton_id: The ID of the mitigation.
        :returns: A list of mitigated attacks (can be empty).
    """
    global attack_dict

    attacks = []
    for atk in attack_dict.values():
        if atk['mitigations'] is not None:
            # There are some mitigations to iterate over
            for mtg in atk['mitigations']:
                if mtg['mitigation'] is not None and mitigation_id == mtg['mitigation']['id']:
                    # We're ignoring "out of scope" mitigations in this view
                    attacks.append({
                            'identifier': atk['identifier'],
                            'auto_identifier': atk['auto_identifier']
                    })
                    attacks.extend(get_child_attacks(atk))
                    if atk['is_abstract']:
                        attacks.extend(get_instance_attacks(atk))

    return natsorted(attacks, key=lambda attack: attack['auto_identifier'] or '')

def build_mitigation_table():
    """ Build a LaTeX tabularray long table for the system mitigations.

        :returns: A LaTeX table in the form of a list of lines (strings).
    """
    lines = []
    lines.append('\\begin{longtblr}{width=\\textwidth, colspec={||X[-1,halign=l,valign=m]|X[3,halign=l,valign=m]|X[-1,halign=l,valign=m]||}, rowhead=1, cells={font=\\fontsize{9pt}{10pt}\\selectfont}, row{1}={font=\\bfseries}}')
    lines.append('\\hline')
    lines.append('Mitigation & Description & Attacks \\\\*')
    lines.append('\\hline')
    sorted_mitigations = natsorted(mitigation_dict.values(), key=lambda mitigation: mitigation['auto_identifier'] or '')
    for mitigation in sorted_mitigations:
        auto_id = mitigation['auto_identifier']
        description = create_links_in_line(sanitize_text(mitigation['description']))
        attacks = get_mitigation_attacks(mitigation['id'])
        attacks_text = ''
        for a in attacks:
            attacks_text = attacks_text + f'{{{a['identifier']}}}' + ', '
        if len(attacks_text) > 0:
            # remove the final ", "
            attacks_text = attacks_text[:-2]
        attacks_text = create_links_in_line(attacks_text)
        lines.append(f'\\hypertarget{{{auto_id}}}{{{auto_id}}}. {mitigation['name']} & {description} & {attacks_text} \\\\')
        lines.append('\\hline')
    lines.append('\\end{longtblr}')
    return lines

def get_objectives(attack):
    """ Find the security objectives targeted by the specified attack.

        :param attack: The attack.
        :returns: A list of targeted security objectives (can be empty).
    """
    result = []
    if attack['properties'] is not None:
        for p in attack['properties']:
            result.append(p['auto_identifier'])
    return result

def objectives_match_prefix(attack, prefixes):
    """ Determine whether the security objectives targeted by the specified
        attack match one of of the specified prefixes.

        :param attack: The attack.
        :param prefixes: The prefixes to check.
        :returns: True if the security objectives match, False otherwise.
    """
    objectives = get_objectives(attack)
    for o in objectives:
        for p in prefixes:
            if o.startswith(p):
                return True
    return False

def get_mitigations(attack):
    """ Get all the mitigations for the specified attack, or declare it out
        of scope.

        :param attack: The attack.
        :returns: A list of mitigations, sorted by auto-identifier.
    """
    result = []
    for mit in attack['mitigations']:
        if mit['mitigation'] is None:
            # out of scope
            result.append({
                'auto_identifier': None,
                'name': 'Out of Scope',
                'rationale': mit['rationale']
            })
        else:
            result.append({
                'auto_identifier': mit['mitigation']['auto_identifier'],
                'name': mit['mitigation']['name'],
                'rationale': mit['rationale']
            })
    if len(result) == 0 and attack['instance_of'] is not None:
        # if there's still no mitigation, but this is an instance of an
        # abstract attack, refer to the abstract attack mitigations
        abs_attack_ref = '{' + attack['instance_of']['name'] + '}'
        result.append({
            'auto_identifier': None,
            'name': f'See mitigations for {abs_attack_ref}',
            'rationale': ''
        })

    result = natsorted(result, key=lambda m: m['auto_identifier'] or '')
    return result

# build attack/mitigation table for attacks against properties with specific prefixes,
# or (if no prefixes specified) abstract attacks
def build_attack_mitigation_table(prefixes, show_mitigations=False, attack_anchors=False):
    """ Build a LaTeX tabularray long table for attacks and (optionally) mitigations.

        :param prefixes: The prefixes, as a list of strings.
        :param show_mitigations: True to show mitigations in the table, defaults to False.
        :param attack_anchors: True to make LaTeX hyperref anchors for the attacks, defaults to False.
        :returns: The table, as a list of strings.
    """

    # We assume no duplicate or overlapping prefixes, and thus no duplicate attacks in
    # the filtered attacks list; if the prefixes list is empty, we assume we want to
    # show the abstract attacks
    global attack_dict
    abstract_attacks = (len(prefixes) == 0)
    table_width = 2 if abstract_attacks else 3
    lines = []
    if abstract_attacks:
        # we don't show targeted objectives for abstract attacks
        lines.append('\\begin{longtblr}{width=\\linewidth, colspec={||X[-1,halign=l,valign=m]|X[halign=l,valign=m]||}, rowhead=1, cells={font=\\fontsize{9pt}{10pt}\\selectfont}, row{1}={font=\\bfseries}}')
    else:
        lines.append('\\begin{longtblr}{width=\\linewidth, colspec={||X[-1,halign=l,valign=m]|X[-1,halign=l,valign=m]|X[halign=l,valign=m]||}, rowhead=1, cells={font=\\fontsize{9pt}{10pt}\\selectfont}, row{1}={font=\\bfseries}}')
    lines.append('\\hline')
    header_attack = 'Attack' if abstract_attacks else 'Attack (Context)'
    header_description = 'Description'
    if show_mitigations:
        header_attack = header_attack + ' / \\emph{Mitigation}'
        header_description = header_description + ' / \\emph{Rationale}'
    if abstract_attacks:
        lines.append(f'{header_attack} & {header_description} \\\\*')
    else:
        lines.append(f'{header_attack} & Objective & {header_description} \\\\*')
    lines.append('\\hline')
    filtered_attacks = []
    filtered_attacks.extend(a for a in attack_dict.values() if (abstract_attacks and a['is_abstract']) or objectives_match_prefix(a, prefixes))
    sorted_attacks = natsorted(filtered_attacks, key=lambda attack: attack['auto_identifier'] or '')
    parent = None
    for attack in sorted_attacks:
        # if the parent has changed, make a table line for it; we don't do this
        # for abstract attacks
        if not abstract_attacks and len(attack['parents']) == 1 and attack['parents'][0] != parent:
            parent = attack['parents'][0]
            auto_id = parent['auto_identifier']
            name = parent['name']
            attack_id = auto_id
            if attack_anchors:
                attack_id = f'\\hypertarget{{{auto_id}}}{{{auto_id}}}'
            lines.append(f'\\SetCell[c={table_width}]{{m}}{attack_id}.~{name} \\\\*')
            lines.append('\\hline')
        if attack['description'] is None and len(attack['children']) > 0:
            # Attacks without descriptions that have children don't get printed
            # on lines by themselves with description cells; they'll be printed
            # as parents, in the above "if"
            continue
        auto_id = attack['auto_identifier']
        description = create_links_in_line(sanitize_text(attack['description'] or ''))
        name = create_links_in_line(sanitize_text(attack['name']))
        ctxt = ''
        if attack['context'] is not None:
            ctxt = create_links_in_line(f'({attack['context']['identifier']})' or '')
        if abstract_attacks:
            objectives_text = ''
        else:
            objectives = get_objectives(attack)
            objectives_text = '& '
            for o in objectives:
                objectives_text = objectives_text + f'{{{o}}}' + ', '
            if len(objectives_text) > 0:
                # remove the final ", "
                objectives_text = objectives_text[:-2]
            objectives_text = create_links_in_line(objectives_text)
        attack_id = auto_id
        if attack_anchors:
            attack_id = f'\\hypertarget{{{auto_id}}}{{{auto_id}}}'
        # don't break a page between an attack and its mitigations
        mitigations = []
        nobreak = ''
        if show_mitigations:
            mitigations = get_mitigations(attack)
            if len(mitigations) > 0:
                nobreak = '*'
        leftskip = '' if abstract_attacks and len(attack['parents']) == 0 else '\\leftskip=1em'
        lines.append(f'{leftskip} {attack_id}.~{name} {ctxt} {objectives_text} & {{{description}}} \\\\{nobreak}')

        # add table lines for the attack mitigations, if necessary
        if show_mitigations:
            for mit in mitigations:
                # we don't write "OOS" identifier in LaTeX, to save space
                auto_id = ''
                if mit['auto_identifier'] is not None:
                    auto_id = f'\\hyperlink{{{mit['auto_identifier']}}}{{{mit['auto_identifier']}}}.~'
                name = create_links_in_line(sanitize_text(mit['name']))
                rationale = create_links_in_line(sanitize_text(mit['rationale'] or ''))
                lines.append('\\hline[dash=dotted]')
                cell_skip = '\\SetCell[c=2]' if table_width == 3 else '\\SetCell'
                middle_cell = '&' if table_width == 3 else ''
                nobreak = '*'
                if mit == mitigations[-1]:
                    nobreak = ''
                lines.append(f'{cell_skip}{{m,preto=\\hspace{{1em}}}} \\emph{{{auto_id}{name}}} {middle_cell} & \\emph{{{rationale}}} \\\\{nobreak}')

        lines.append('\\hline')

    lines.append('\\end{longtblr}')
    return lines

def write_lines_to_file(lines, filename):
    """ Write a list of lines to a file, adding a UNIX newline after each line.

        :param lines: The lines to write.
        :param filename: The name of the file to write.
    """
    global output_file_path

    p = Path(output_file_path, filename)
    try:
        with p.open(mode='w') as f:
            for line in lines:
                f.write(f'{line}\n')
    except Exception:
        print("error writing output file, aborting")
        exit(1)

def main():
    global property_dict
    global context_dict
    global mitigation_dict
    global attack_dict
    global output_file_path

    parser = argparse.ArgumentParser(description='Generate LaTeX input files for threat model')
    parser.add_argument('-d', '--database', type=str, help='Path to the SQLite database file',  nargs='?', default="db.sqlite3")
    parser.add_argument('-o', '--output', type=str, help='Path to write the generated LaTeX files', nargs='?', default='.')
    args = parser.parse_args()

    db_file_path = args.database
    output_file_path = args.output

    # Build data structures
    property_dict, context_dict, mitigation_dict, attack_dict = build_data_structures(db_file_path)

    # Generate property trees, one for each "root" property (not actual roots, because
    # INTEGRITY is a root but we really want its 3 sub-properties)
    root_names = ["AVAILABILITY", "CONFIDENTIALITY", "CORRECTNESS", "VERIFIABILITY"]
    root_properties = [prop for prop in property_dict.values() if prop['name'] in root_names and prop['kind'] == 'Model']

    for root in root_properties:
        property_list = build_property_list(root)
        property_name = str.lower(root['name'])
        write_lines_to_file(property_list, f'{property_name}_tree.tex')

    # Generate DISPUTE_FREENESS trees (really lists)
    # First, one excluding D3
    df_property = [prop for prop in property_dict.values() if prop['name'] == 'DISPUTE_FREENESS' and prop['kind'] == 'Model']
    d1_d2_list = build_property_list(df_property[0], excludes=['D3'])
    write_lines_to_file(d1_d2_list, 'd1_d2_tree.tex')
    # And then, one excluding D1/D2
    d3_list = build_property_list(df_property[0], excludes=['D1', 'D2'])
    write_lines_to_file(d3_list, 'd3_tree.tex')

    # Generate context table
    context_table = build_context_table()
    write_lines_to_file(context_table, 'context_table.tex')

    # Generate attack mitigation tables for individual attack prefixes
    attack_prefixes = [['C'], ['V'], ['D1', 'D2'], ['D3'], ['P'], ['A']]
    for prefixes in attack_prefixes:
        attack_table = build_attack_mitigation_table(prefixes, show_mitigations=True)
        prefix_name = str.lower('_'.join(prefixes))
        write_lines_to_file(attack_table, f'{prefix_name}_attack_mitigation_table.tex')

    # Generate attack mitigation table for abstract attacks
    abstract_attack_table = build_attack_mitigation_table([], show_mitigations=True, attack_anchors=True)
    write_lines_to_file(abstract_attack_table, 'abstract_attack_table.tex')

    # Generate attack table for all attacks
    all_attack_prefixes = ['C', 'V', 'D', 'P', 'A']
    all_attack_table = build_attack_mitigation_table(all_attack_prefixes, attack_anchors=True)
    write_lines_to_file(all_attack_table, 'all_attack_table.tex')

    # Generate mitigation table
    mitigation_table = build_mitigation_table()
    write_lines_to_file(mitigation_table, 'mitigation_table.tex')

if __name__ == "__main__":
    main()
